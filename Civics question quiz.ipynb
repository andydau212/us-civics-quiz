{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ab1295",
   "metadata": {},
   "source": [
    "## Actually Creating the Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e67d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_quiz import QAs\n",
    "\n",
    "with open('data.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "question_bank = QAs(**json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae49f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "class Quiz:\n",
    "    asked = set()\n",
    "    question_bank: QAs\n",
    "    llm: ChatOpenAI\n",
    "        \n",
    "    def __init__(self, question_bank):\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo', max_tokens=1500)\n",
    "        self.question_bank = question_bank\n",
    "        \n",
    "    def quiz_and_give_answer(self):\n",
    "        if len(self.asked) == 100:\n",
    "            print(\"All questions asked. You're done!\")\n",
    "            return True\n",
    "        random_index = random.randint(0, len(self.question_bank.items) - 1)\n",
    "        while random_index in self.asked:\n",
    "            random_index = random.randint(0, len(self.question_bank.items) - 1)\n",
    "        self.asked.add(random_index)\n",
    "        qa = self.question_bank.items[random_index]\n",
    "        user_answer = input(qa.question + \" Answer: \")\n",
    "        check_answer_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"answer\", \"user_answer\"],\n",
    "            template=\"You will be given a pair of question and answer, as well as a user's answer. Return if the user's answer is correct or not and explain why. Question: {question}\\n Answer: {answer}\\n User's answer: {user_answer}\",\n",
    "        )\n",
    "        chat_input = check_answer_prompt.format_prompt(question=qa.question, answer=qa.answer, user_answer=user_answer)\n",
    "        response = self.llm.predict(chat_input.to_string())\n",
    "        print(response)\n",
    "        return False\n",
    "    \n",
    "    def run_quiz(self):\n",
    "        finished = False\n",
    "        while not finished:\n",
    "            finished = self.quiz_and_give_answer()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Quiz(question_bank=question_bank)\n",
    "a.run_quiz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1fd82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
